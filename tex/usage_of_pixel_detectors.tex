There always was a tight relation between the development of cameras and pixel detectors since 1969, when the idea of CCDs, thanks to whom Boyle and Smith were awarded the Nobel Prize in Physics in 2009, revolutionized photography allowing light to be captured electronically instead of on film. 
Even though the CMOS technology was already known when CCDs spread, the costs of productions were too high to allow the diffusion of these sensors for which needed to wait untill 1990s. From that period on, the fast diffusion of CMOS was mainly due to the less cost than CCD, and the less power required for supply. Nowadays CCDs are still prefered over MAPS in astronomy, where the astronomical sources' rate are low enough to cope with tens of \si{ms} for the readout.  

The principal use cases of pixel detectors are particle tracking and imaging: in the former case individual charged particles have to be identified, in the latter instead an image is obtained by the usually un-triggered accumulation of the impinging radiation. 
Also the demands on detectors performance depends on their usage, in particular tracking requires high spatial resolution, fast readout and radiation hardness. 


\section{Tracking in HEP}
    At first the physics world overlooked the CCDs, and all pixel in general, as against the gaseous detector for tracking: there was no need to replace these ones which had a sufficient good resolution (\SI{100}{\um}). Sice 1974, with the measurement of the invariant mass of the \red{j psi} and the affirmation of the quark model, all experiments start to look for better spatial resolutions in order to achieve the possibility of reconstructing short lived particle.  

    Historically, the first pixel detector employed in particle physics was a CCD: it was installed in the spectrometer at the CERN’s Super Proton Synchrotron (SPS) by the ACCMOR Collaboration (Amsterdam, CERN, Cracow, Munich, Oxford, RAL) at mid 1980s, with the pourpose of studing the recently-discovered charm particles.
    The second famous usage of CCDs took place at SLAC in the Large Detector (SLD) during the two years 1996-98. 
    \red{Cosa vedono di così importante da dire che servono i pixel detector?}
    From that period on particle tracking in experiments have been transformed radically: it was mandatory for HEP experiments to build a inner vertex detector. 
    In 1991, the more demanding environments led to the development of hybrid pixel detectors: a dedicated collaboration, RD19, was established at CERN with the specific goal to define a semiconductor micropattern detector with an incorporated signal processing at a microscopic level. 
    In those years a wide set of prototypes of hybrid pixel has been manufactured; among the greatest productions a mention goes to the huge ATLAS and CMS vertex detectors. 
    From the middle of 2013 a second collaboration, RD 53, has been established with the new goal to find a pixel detector suitable for phase II future upgrades of those experiments. Even if the collaboration is specifically focused on design of hybrid pixel readout chips (aiming to \SI{65}{nm} tecnique so that the electronics fits within the pixel area), also other options have been taken in account and many test have been done on MAPS for example. Requirements imposed by HL-LHC will become tigher in time: for example, a dose and radiation of \SI{5}{Mrad} and \si{10 {16}}{NIEL} are exepcted after 5 years of operation. Time resolution, material budget and power consumption are also issues for the upgrade: a time resolution better than \SI{25}{ns} for a bunch crossing frequency of \SI{40}{MHz}, a material budget lower than 2\% and a power consuption lower than  \SI{500}{mW/cm\squared} are required. 

    Amidst the solutions proposed 3D silicon detector, invented by Sherwood Parker in 1995, and MAPS are the most promising. In 3D sensors the electrode is a narrow column of n-type implanted vertically across the bulk instead of being implanted on the wafer's surface. 
    The charge produced by the impinging particle is then drifted transversally within the pixel, and, as the mean path between two electrode can be soufficent low, the trap probability is not an issue. 
    3D pixels have been already proved in ATLAS tracker \red{quando?}. 
    Even if 3D detector are adequately radiation hard, MAPS architecture looked very promising from the beginning: they overcome both the CCDs long reading time and the hybrid problems (I have already explained in section \ref{sec:} the benefits of MAPS). 
    Experiments such as ALICE at LHC and STAR at RHIC have already introduced the CMOS MAPS technology in their detectors. ALICE Tracking System (ITS2), upgraded during the LHC long shut down in 2019-20, was the first large-area ($\sim$10 \si{m\squared} covered by 2.5 Gpixels) silicon vertex detector based on CMOS MAPS.

    \subsection{Hybrid pixels at LHC and at SuperKEKB}
        \subsubsection{ATLAS}    
        With CMS, ATLAS is one of two general-purpose detectors at the LHC and has the largest volume detector ever constructed for a particle
        collider (\SI{46}{m} long and \SI{25}{m} in diameter).  
        The Inner Detector consists of three different systems all immersed in a magnetic field parallel to the beam axis whose main components are: the pixel, the micro-strips and transition radiation trackers. Concerning the pixel detector, 92 million pixels are divided in 4 barrel layers and 3 disks in each end-cap region, covering a total area of \SI{1.9}{m\squared} and having a \SI{15}{kW} of power consumption.

        As stated by the ATLAS collaboration the pixel detector is exposed by an extreme particle flux: "By the end of Run 3\footnote{Run 3 start in June 2022}, the number of particles that will have hit the innermost pixel layers will be comparable to the number it would receive if it were placed only a few kilometres from the Sun during a solar flare". Considering that the particle density will increase even more with HL-LHC, radiation hardness is definitively target to achieve. 

        The most ambitious goal is employ a MAPS-based detector for the inner-layer barrels, and for this reason the RD53 collaboration is performing many test on MAPS prototypes, as Monopix of which I will talk about in section \ref{sec:}.
        
        Up to now this possibility will be eventualy implemented during the second phase of the HL-LHC era, as at the start of high-luminosity operation the selected option is the hybrid one. The sensor will be bonded with ITkPix, the first full-scale \SI{65}{nm} hybrid pixel-readout chip developed by the RD53 collaboration.
        Regarding the sensor, a valueable option is using 3D pixels, which have already proved themselves in ATLAS, for the insertable B layer (IBL).\red{qualcosa in più sui 3d.}
        The number of pixels will be increased of a factor about 7, passing from 92 milions to 6 billion.
    
        %3D silicon sensor technology has been chosen to instrument the innermost pixel layer of ITk, which is the most exposed to radiation damage. 50  50 and 25  100 .D
        %sensors are an established technology that has been already
        %employed in experiments at the LHC such as in the ATLAS
        %Insertable B-Layer (IBL)  and for the tracker of the AFP
        %experiment . With respect to these designs the new ITk 3D
        %sensors feature a reduced pixel cell size of 25  100 and 50 
        %50 um 2 with one collecting electrode .  active substrate of these new
        %sensors is reduced to 150 um in comparison to the previous
        %generation of 230 um thick 3D sensor
        \subsubsection{CMS}
        \red{da scrivere}
        124 million pixels; cylindrical layers roughly at 3cm, 7cm, 11cm and 16cm and disks at either end, and so will be vital in reconstructing the tracks of very short-lived particles. Each of these silicon pixels is 100um by 150um,even with  only around 50 microwatts per pixel, the total power output is 7.5kW-

        \subsubsection{LHCb}
        LHCb is a dedicated heavy-flavour physics experiment that exploits pp interactions at \SI{14}{TeV} at LHC. 
        It was the last experiment to upgrade the vertex detector, the Vertex Locator (VELO), replacing the silicon-strip with pixels in May 2022. 
        As the instantaneous luminosity in Run3 is increased by a factor $\lesssim$10, much of the readout electronics and of the trigger system have been developed in order to cope with the large interaction rate.
        To place the detector as close as possible to the beampipe and reach a better track reconstruction resolution, the VELO has a surprising feature: it can be moved. During the injection of LHC protons it is parket at \SI{3}{cm} from the beams and only when the stability is reach it is brought at $\sim$\SI{5}{mm}. Radiation hardness as well as readout speed are then a priority for the detectors: that's why the collaboration opted for a hybrid system. 
        The Velopix is made bonding sensors, each measuring 55 $\times$ 55 micrometers, \SI{200}{\um}-thick to a \SI{200}{\um}-thick ASIC specially developed for LHCb and coming from the Medipix family (sec. \ref{sec:}), which can handles hit rates up to \SI{900}{MHz} per chip.
        Since the detector is operated under vacuum near the beam pipe, the heat removal is particularly difficult and evaporative CO2 microchannel cooling are used. 

    \subsubsection{BelleII}
        The current vertex detector of BelleII, VXD, is made of a pixel detector (PXD), fabricated with 2 layers of DEPFET-based pixels, and 4 layers of a double-sided silicon strip detectors (SVD)\cite{BelleII-DEPFET}.
        Due to the small capacitance of the collection node, DEPFET presents a high signal-to-noise ratio (in 30-50) thanks to the low instrinsic noise and to the large signal achieved with he fully depleted bulk: pixels are thinned to \SI{75}{\um} in the active region, then a MIP is supposed to create a signal of $\sim$\SI{6000}{e^-}, while the typical noise of DEPFET is around \SI{200}{e^-}.
        \red{The ASIC read out is still based on a rolling shutter logic, with an integration time of \SI{20}{\us}.}
        In order to reduce the data-storage memory PXD hits are only used to improve spatial resolution of tracks: the SVD informations are used by the High Level Trigger (HLT) to look for regions of interest in the pixel ladders just by extrapolating back the tracks found in the tracker detector, and this method allows to store only data belonging to these areas; the PXD hits are then used in offline track fit to improve the vertex resolution.
        
        MAPS have been proposed for the replacement of VXD during the  Long Shut Down 2 (LSD2) foreseen around 2026-27; the new vertex detector, VTX, should be made of 5 layers fabricated by the optimized Belle II pixel sensor (OBELIX), a detector based on TJ-Monopix have been selected (look at chapter \ref{chapter:Monopix}).    
        The main advantages VTX should bring are a obvious improving in the track and vertex resolution (\SI{14}{\um} before upgrade, $\lessapprox$\SI{10}{\um} expected after upgrade) and a reduction in the $X_0$ (\red{da.. a..}), a higher background tolerance because of the smaller sensor than strips dimension and a low bandwidth due to the on-chip sparsification. 

    \subsection{First attempts to MAPS}
        \subsubsection{MIMOSA at EUDET and STAR}
        MIMOSA \cite{MIMOSA}\cite{MIMOSA26} (standing for Minimum Ionizing MOS Active pixel sensor), designed in 2008, prefigured the architecture of MAPS for coming vertex detector being the first large scale sensor to be embloyed as detector. MIMOSA-26 equiped the final version of EUDET high resolution  beam telescope both at CERN-SPS and at DESY while the MIMOSA-28 devices are used for the first MAPS-based vertex detector at the STAR experiment.
        MIMOSA-26 is fabricated in a \SI{350}{nm}, and a module features 1152 columns, split into 18 indipendent groups, and 576 rows, with square pixels having a side of \SI{18.4}{\um} lenght; therefore, beacuse of the small dimension, charge sharing is an issue \red{aggiungi qualcosa}. 
        The readout is done in a rolling shutter mode: the chip is an Active Pixels (APS) and therefore it incorporates the amplification on pixel, while the signal discrimination and zero-suppression logic are placed at the EoC, where is also placed a memory.
        The chip is an Active Pixels (APS) and therefore it incorporates the amplification on pixel, while the signal discrimination and zero-suppression logic are placed at the EoC: the readout is done in a rolling shutter mode with a frame integration time that can be lowered down to \SI{85}{ms}, and a memory allowing to store up to six hits is. 

        The EUDET telescope, equipped with six sensor planes, requires highly granular and thin pixel detectors in order to achieve an excellent track resolution (around \SI{2}{\um}) even at the rather low particle energies of up to \SI{6}{GeV}.
        The STAR experiment at the Relativistic Heavy Ion Collide (RHIC) accelerator at the Brookhaven National Laboratory (BNL) is the first to include MAPS in the vertex detector\cite{STAR}.
        The main tracking detector in STAR is a TPC with radii 60-190 cm  embedded in a \SI{0.5}{T} solenoidal magnetic field, that provides a pointing resolution of approximately \SI{1}{mm}. 
        The pixel detector, PXL, is a part of a 3-detector system, Heavy Flavor Tracker (HFT), that has been added to the pre-existing STAR apparatus just before the 2014 Run in order to improve the impact parameter resolution and to enable the direct reconstruction of hadronic decays of heavy flavor mesons and baryons.     
        The Heavy Flavor Tracker (HFT) is composed by the Silicon Strip Detector (SSD), the Intermediate Silicon Tracker (IST) and the Pixel Detector (PXL); the first one is placed at \SI{22}{cm} from the beam pipe and consists of double sided strips with \SI{95}{\um} inter-strip pitch, the second one, placed at \SI{14}{cm}, is made of single sided silicon pads with \SI{600}{\um}$\times$\SI{6}{mm} pitch and the last one made by two layes is placed at \SI{2.8}{cm} and \SI{8}{cm} fabricated with ULTIMATE2 (also known as MIMOSA-28), a successor of MIMOSA-26 sensor, with pitch \SI{20.7}{\um} and thinned down to \SI{50}{\um}.
        An area of \SI{0.16}{m\squared} are covered by 400 MAPS sensor, corresponding to 356 milions of pixels divided into array size of 928 $\times$ 960.
        Each pixel includes circuitry for readout, amplification, and Correlated Double Sampling (CDS) for signal extraction and noise subtraction and the frame integration time is \SI{185.6}{\us}; after the subtraction the signal to noise ratio is $\sim$ 30, with a noise between 10-12 electrons and a signal of \SI{1000}{e^-}.
        Thanks to the HFT system and the PXL, STAR achieved a track pointing resolution \SI{46}{\um} for \SI{750}{MeV/c} kaons, and better than \SI{30}{\um} for particle momenta bigger than \SI{1}{GeV/c}: this performance enabled the study of D-meson production with a high significance signal.
        \begin{figure}[h!]
            \begin{subfigure}{.4\textwidth}
            \centering
            \includegraphics[width=.98\linewidth]{figures/pixel_detectors_usage/MIMOSA.png}
            \end{subfigure}
            \begin{subfigure}{.6\textwidth}
                \centering
                \includegraphics[width=.98\linewidth]{figures/pixel_detectors_usage/STAR.png}
            \end{subfigure}
            \caption{(a) The HFT PXL detector; (b) Block-diagram of the ULTIMATE-2 sensor}
            \label{fig:}
        \end{figure}

        \subsubsection{ALPIDE at ALICE}
        ALICE (A Large Ion Collider Experiment) is a detector dedicated to heavy-ion physics and to the study of the condensed phase of the chromodynamics at the LHC.
        The tracking detector consists of the Inner Tracking System (ITS), the gaseous Time Projection Chamber (TPC) and the Transition Radiation Detector (TRD),  and all those are embedded in a magnetic field of \SI{0.5}{T}. The ITS is made by six layers of detectors, two for each type, from the interaction point outwards: Silicon Pixel Detector (SPD), Silicon Drift Detector (SDD) and Silicon Strip Detector (SSD).         
        Contrary to the others LHC experiments, ALICE tracker in placed in a quite different environments: the expected dose is smaller by two order of magnitude and the rate of interactions is few \si{MHz} instead of \SI{40}{MHz}, but the number of particles comes out of each interaction is higher (the SPS is invested by a density of particles of $\sim$\SI{100}{\per cm\tothe{-2}}).  
        The reconstruction of very complicated events whit a large number of particle is a challenge, hence to segment and to minimize the amount of material, which may cause secondary interaction complicating futher the event topology, is considered a viable strategy. 
        The detector employes the ALPIDE chip, developed by ALICE collaboration, fabricated in the 180 nm CMOS Imaging Sensor process of TowerJazz, whose design takes full advantage of process feature which allows full circuitry within the pixel matrix.
        Thanks to the reduction of the material budget, ITS2 obtained an amazing improvement both in the position measurement and in the momentum resolution, improving the efficiency of track reconstruction for particle with very low transverse momentum (by a factor 6 at pT $\sim$ 0.1 GeV/c). Further advancements in CMOS MAPS technology are being aggressively pursued for the ALICE ITS3 vertex detector upgrades (foreseen around 2026-27), with the goals of further reducing the sensor thickness and improving the readout speed of the devices, while keeping power consumption at a minimum.

\section{Other applications}
    Historically for imaging pourpose the CCDs were the favoured device: they can be used as single photon counter or integrating and collecting the charge released by more impinging particles. The utilisation in the first case is similar to the tracking one, except that the requirements are less tight, so much that two noteworthy of microchips originally meant for detectors in particle physics at the LHC, and later employed in other fields are Medipix and Timepix. They are read-out chips developed by the Medipix Collaborations since early 1990s. For two decades, different Medipix generations have been produced, having a rough correlation with the feature size used: Medipix2 (1999) used \SI{250}{nm} feature size CMOS while Medipix3 (2005) \SI{130}{nm}.
    The aim of the fourth collaboration (2016), instead, is designing pixel read-out chips that prepared for \red{TSV processing and may be tiled on all four sides. DOVREI METTERE DUE RIGHE SU TSV OPPURE TAGLIARE. }
    For photons imaging other materials with higher atomic charge than silicon could be prefered, as a high photon absorption efficiency is needed: it was for this reason that Medipix2 was bump bonded to identically segmented sensors of both silicon and GaAs.
    
    The applications in scientific imaging vary from atrophysics and medical imaging to more exotic domains as studies of protein dynamics, art authentication and dosimetry.
    The most important employment of Medipix is as X-ray single photon counting in industrial and medical radiography and in 3D computed tomography. 
    Thanks to a New-Zealand company, the MARS Bioimaging detector has been fabricated, which is capable of resolving the photons energy and produce 3D coloured images.
    Besides tracking in HEP (I have already cited the use of Timepix3 is in the beam telescope of the LHCb VELO), an important use of Timepix is in dosimetry \red{Timepix Detector for Imaging in Ion Beam Radiotherapy- aggiungi qualche info}
    A small-Timepix detector with the dimension of a USB can also be found at the International Space Statio, where it is exploited for radiation, principally made of haevy-ion, monitoring. 
 
    \subsection{Applicability to FLASH radiotherapy}
        A possible new application of pixels detector is dosimetry or beam monitoring of charge particles in high intensity radiography.
        The radiological treatment is a common method used in 60\% of tumors both as palliative care and as treatment. It can be given before, after or during a surgery, (Intra operative radiation therapy-IORT) and many different types of radiations (photons, electrons, protons and ions, which mainly are hydrogen and carbon) can be used to irradiate the affected tissues.
        Exploiting the ionizating energy loss, that can be parametrized by the Linear Energy Transfer (LET), a biological damage can be delivered to the tissue: while $\alpha$ and $\beta$ particles are high LET radiations with values in \SIrange{100}{200}{keV/\um}, x-rays and gamma-rays are low LET radiations with values in range \SIrange{0.2}{2}{keV/\um}.

        If x-ray photons, with energy in \SIrange{4}{25}{MeV} are used, the ionization is caused by the Compton electrons and is more in the superficial layers of the tissue due to the exponential attenuation of the beam. 
        The hardrons energy loss, instead, is strongly localized in the last region of the track, that is the Bragg peak. 
        Ion beam enables better focusing of the radiation thereby improves the sparing of the surrounding healthy tissues; on the other hand the delivered dose distribution depends more on the patient's density tissues (e.g. bones, swelling, fat). 
        \red{Ensuring the target coverage is a fundamental objective in radiotherapy and is closely connected to the choice of the particles. Electrons cover the target since they tend to spread out and can cover a field size of a few cm2 at a distance of a few cm from the source. Instead, the limited size of the beam for protons and photons from ultra high dose rate microbeam radiation therapy (MRT), for which FLASH effect was seen, requires the scanning of target.
        The radiobiological consequences of scanning both in spatial-fractionation and in prolonged exposure, which might not be sufficient to maintain a high mean dose rate to trigger FLASH effect, need to be explored.
        To date, the FLASH effect has been most commonly demonstrated using low-energy electron linacs}

        \begin{figure}
            \centering
            \includegraphics[width=.7\linewidth]{figures/pixel_detectors_usage/Bragg-Peak.png}
            \caption{The Spread Out Bragg Peak (SOBP) curve (green), which is a constant dose distribution, is obtained from the superposition of many Bragg peak of hadrons with different energy.}
            \label{fig:Bragg-peak}
         \end{figure}

        Recently\footnote{The first evidences has been observed on a mice experiments in 1966 and in 2014 by the group of Favaudon and Vozenin. After this, many test on cats and pigs have been performed, and also there has been a clinical trial on a cutaneous tumor-patient} a promising method for RT at ultra high dose rate (at least \SI{40}{Gy/s}) and for this reason called FLASH-RT\cite{FLASH_review}, instead of CONV-RT (\SI{0.03}{Gy/s}), came out. 
        \begin{table}
            \begin{center}
            \begin{tabular}{|c | c |c |}
            \hline
            & CONV-RT & FLASH-RT \\
            \hline
            \hline
            Dose rate & \SI{0.03}{Gy/s} & \SI{40}{Gy/s}\\
            Intra pulse dose rate & \SI{100}{Gy/s}&\SI{10 6}{Gy/s}\\
            Treatment duration & $\sim$minutes & $\lessapprox$\SI{500}{ms} \\
            DDP & \SI{0.3}{mGy} & \qtyrange{1}{10}{Gy}\\
            Pulse width & \SI{3}{\us} & $\sim$\SI{2}{\us} \\
            \hline
            \end{tabular}
            \caption{Typical value of treatment parameters}
            \label{tab:dose_parameters}
            \end{center}
         \end{table}
        This treatment takes advantages of biological differences between tumors and healthy tissues: it is characterized by reducing normal tissue toxicity and maintaining equivalent tumor damage. 
        The response to dose can be described by the survival fraction probability, describing the fraction of surviving cell as a function of the dose: 
        \begin{equation}
            S(D) = S(0)\;e^{-( \alpha D \, + \, \beta D^2)}
            \label{eq:survival_curve}
        \end{equation}
        where $\alpha$ and $\beta$ respectively represents the rate of cell killing by single ionizing events and by double hits. 
        Hence, at high doses the density of damages increases and the cells repair becomes more difficult. 
        Even if the FLASH effect is not yet completelly understood and the underlying mechanisms are not clear, it looks like there are two different recipes which are involved:
        \begin{itemize}
            \item \textbf{The dose rate:} 
            higher dose rate produce bigger damages (fig. \ref{fig:damage_vs_dose}(a)) since this prevent cells from sparing.
            \item \textbf{The presence or absence of oxygen:} 
            while hypoxic cells are very resistant to
            radiation, normal oxygenated cells are highly radiosensitive. 
            This is because if molecules containing $O_2$ break due to the impinging radiation, then the oxygen can build Reactive Oxygen Species (ROS) (fig.\ref{fig:damage_vs_dose}(b))
        \end{itemize}    
        \begin{figure}[h!]
            \begin{subfigure}{.5\textwidth}
            \centering
            \includegraphics[width=.98\linewidth]{figures/pixel_detectors_usage/survival_curve.png}
            \end{subfigure}
            \begin{subfigure}{.5\textwidth}
                \centering
                \includegraphics[width=.80\linewidth]{figures/pixel_detectors_usage/survival_curve_oxygen.png}
            \end{subfigure}
            \caption{(a) Survival curve for different dose rate and (b) for different oxygen cell content}
            \label{fig:damage_vs_dose}
        \end{figure}

        The Tumor Control Probability (TCP) and the Normal Tissue Complication (NTC) functions parametrize respectively the efficiency of damaging on the tumor after having released a certain dose and the probability of not affecting the healthy tissues. The intermediate zone between the increase of the TC and of the NTC is called therapeutic window, and the wider it is and the more effective the treatment is. 
        \begin{figure}
            \centering
            \includegraphics[width=.7\linewidth]{figures/pixel_detectors_usage/curve_flash.png}
            \caption{Illustration of dependence of TCP, NTCP and therapeutic window on dose, for CONV-RT ad FLASH-RT.}
            \label{fig:therapeutic_window}
        \end{figure}

    \subsubsection{Dosimetric problems}
        Finding dosimeters suitable for online monitoring of the beam at ultra high dose rate is still an open issue since almost all standard online dosimeters show saturation problems.
        Differently, radiochromic films, which are the standard passive dosimeters, show dose-rate indipendece up to \SI{109}{Gy/s}.
        \red{ Cosa sono i radiochromic films and they do not have the same accuracy of other detectors.}
        The principal detectors for reference dosimetry which provide real-time dose measurement are Ionization Chambers (IC), that show saturation issue at dose per pulse (DDP) two orders of magnitude lower than the ones used for FLASH-RT.
        \red{da qui in poi}
        ICs devono essere calibrate secondo la metrologia , per cui grazie a protocolli di calibrazione e introducendo dei fattori correttivi si riesce a fare una misura di dose. $k_{sat}$ which accounts for the loss of charge collected due to recombination.
        Doppi problemi sia di saturazione dovuta a ion recombination sia di scariche, must be carefully accounted for: 
        questo doppio effetto è dato dal fatto che, creandosi tante cariche nella camera, che va ad annullare il campo elettrico di drift. Questo ovviamente paralizza le cariche che non driftano più, ma che anzi si ricombinano ed inoltre facilita la formazione di scariche.
        Per DDP minori di 1 mGy il fattore correttivo è minore al 5\%, poi però aumenta substantially.

        Scintillators have reusable, non-exhaustible scintillation centers. However, the system has a total deadtime given by both the crystal scintillation time and the electronics read-out deadtime.

        Semiconductors show a nonreversible saturation beyond a threshold around 15 cGy/p. The scintillator used, shows a negligible saturation up to 1 Gy/p, but it increases significantly up to at least 11 Gy/p, and it reaches a cutoff value between 11 and 36 Gy/p.

        Scintillator dosimeters are widely used in radiotherapy. They are usually operating in counting-mode where each detected signal is processed by read-out electronics.
        However, the system has a total deadtime given by both the crystal scintillation time and the electronics read-out deadtime
        When a scintillator dosimeter is used in integrator-mode the signal is integrated over the entire irradiation time.A deadtime, due to the decay time of the scintillating material, is considered on average every N recorded pulses, where N is the number of scintillation centres in the dosimeter.


        Besides saturation two other requirements for online dosimeters are high temporal and space resolutions. 
        \red{Si potrebbe pensare di poter usare i pixel detector as beam monitor che hanno risoluzioni spaziali anche inferiori al 10 um e ris temporali -qua dare un valore è più difficile perchè per i maps la risoluzione temporale dipende da l occupancy. Uno dei problemi è però il lungo dead time introdotto dal lungo tempo di readout (ricorrdiamo che sopportano circa 100 Mhz/cm2).}


    
    




